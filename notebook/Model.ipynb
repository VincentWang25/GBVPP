{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T02:33:48.984955Z",
     "start_time": "2021-10-19T02:33:48.966753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T02:33:49.175411Z",
     "start_time": "2021-10-19T02:33:49.167248Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T02:33:50.456414Z",
     "start_time": "2021-10-19T02:33:49.389997Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import FE\n",
    "import dataset\n",
    "import models\n",
    "import util\n",
    "from config import read_config, update_config\n",
    "import train_helper\n",
    "import infer_helper\n",
    "import loss\n",
    "import lrfinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T02:33:50.471221Z",
     "start_time": "2021-10-19T02:33:50.457529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T04:25:07.504757Z",
     "start_time": "2021-10-19T04:25:07.181748Z"
    }
   },
   "outputs": [],
   "source": [
    "config = read_config(\"Fork\")\n",
    "config.gpu = [1]\n",
    "config.train_folds = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T04:25:09.357371Z",
     "start_time": "2021-10-19T04:25:09.340589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of device: 1\n",
      "Model Output Folder: /home/vincent/Kaggle/GBVPP/output/fork/\n"
     ]
    }
   ],
   "source": [
    "config = update_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T02:33:56.928876Z",
     "start_time": "2021-10-19T02:33:51.734125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6036000, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4024000, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>22.509277</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>22.808823</td>\n",
       "      <td>0</td>\n",
       "      <td>11.742872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>0</td>\n",
       "      <td>12.234987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id   R   C  time_step       u_in  u_out   pressure  fold\n",
       "0   1          1  20  50   0.000000   0.083334      0   5.837492     0\n",
       "1   2          1  20  50   0.033652  18.383041      0   5.907794     0\n",
       "2   3          1  20  50   0.067514  22.509277      0   7.876254     0\n",
       "3   4          1  20  50   0.101542  22.808823      0  11.742872     0\n",
       "4   5          1  20  50   0.135756  25.355850      0  12.234987     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>26.320955</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  R   C  time_step       u_in  u_out\n",
       "0   1          0  5  20   0.000000   0.000000      0\n",
       "1   2          0  5  20   0.031904   7.515046      0\n",
       "2   3          0  5  20   0.063827  14.651675      0\n",
       "3   4          0  5  20   0.095751  21.230610      0\n",
       "4   5          0  5  20   0.127644  26.320955      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test = dataset.read_data(config)\n",
    "display(train.shape, test.shape)\n",
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T02:34:42.508008Z",
     "start_time": "2021-10-19T02:34:03.344884Z"
    }
   },
   "outputs": [],
   "source": [
    "train = FE.add_features_choice(train, config)\n",
    "test = FE.add_features_choice(test, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T02:34:42.521947Z",
     "start_time": "2021-10-19T02:34:42.509133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time_step', 'u_in', 'u_out', 'area', 'u_in_cumsum', 'u_in_lag2', 'u_in_lag4', 'R_20', 'R_5', 'R_50', 'C_10', 'C_20', 'C_50', 'ewm_u_in_mean', 'ewm_u_in_std', 'ewm_u_in_corr', 'rolling_10_mean', 'rolling_10_max', 'rolling_10_std', 'expand_mean', 'expand_max', 'expand_std']\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [col for col in train.columns if col not in [\"id\", \"breath_id\", \"fold\", \"pressure\"]]\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T02:34:42.556424Z",
     "start_time": "2021-10-19T02:34:42.522813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "      <th>fold</th>\n",
       "      <th>area</th>\n",
       "      <th>u_in_cumsum</th>\n",
       "      <th>u_in_lag2</th>\n",
       "      <th>...</th>\n",
       "      <th>C_50</th>\n",
       "      <th>ewm_u_in_mean</th>\n",
       "      <th>ewm_u_in_std</th>\n",
       "      <th>ewm_u_in_corr</th>\n",
       "      <th>rolling_10_mean</th>\n",
       "      <th>rolling_10_max</th>\n",
       "      <th>rolling_10_std</th>\n",
       "      <th>expand_mean</th>\n",
       "      <th>expand_max</th>\n",
       "      <th>expand_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618632</td>\n",
       "      <td>18.466375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9.550171</td>\n",
       "      <td>12.939847</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.233188</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>12.939847</td>\n",
       "      <td>9.233188</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>12.939847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>22.509277</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "      <td>0</td>\n",
       "      <td>2.138332</td>\n",
       "      <td>40.975655</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14.172507</td>\n",
       "      <td>11.777738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.658551</td>\n",
       "      <td>22.509277</td>\n",
       "      <td>11.936136</td>\n",
       "      <td>13.658551</td>\n",
       "      <td>22.509277</td>\n",
       "      <td>11.936136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>22.808823</td>\n",
       "      <td>0</td>\n",
       "      <td>11.742872</td>\n",
       "      <td>0</td>\n",
       "      <td>4.454391</td>\n",
       "      <td>63.784477</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16.560977</td>\n",
       "      <td>10.448647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.946119</td>\n",
       "      <td>22.808823</td>\n",
       "      <td>10.766279</td>\n",
       "      <td>15.946119</td>\n",
       "      <td>22.808823</td>\n",
       "      <td>10.766279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>0</td>\n",
       "      <td>12.234987</td>\n",
       "      <td>0</td>\n",
       "      <td>7.896588</td>\n",
       "      <td>89.140327</td>\n",
       "      <td>22.509277</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.571834</td>\n",
       "      <td>9.801731</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.828065</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>10.229525</td>\n",
       "      <td>17.828065</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>10.229525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  time_step       u_in  u_out   pressure  fold      area  \\\n",
       "0   1          1   0.000000   0.083334      0   5.837492     0  0.000000   \n",
       "1   2          1   0.033652  18.383041      0   5.907794     0  0.618632   \n",
       "2   3          1   0.067514  22.509277      0   7.876254     0  2.138332   \n",
       "3   4          1   0.101542  22.808823      0  11.742872     0  4.454391   \n",
       "4   5          1   0.135756  25.355850      0  12.234987     0  7.896588   \n",
       "\n",
       "   u_in_cumsum  u_in_lag2  ...  C_50  ewm_u_in_mean  ewm_u_in_std  \\\n",
       "0     0.083334   0.000000  ...     1       0.083334      0.000000   \n",
       "1    18.466375   0.000000  ...     1       9.550171     12.939847   \n",
       "2    40.975655   0.083334  ...     1      14.172507     11.777738   \n",
       "3    63.784477  18.383041  ...     1      16.560977     10.448647   \n",
       "4    89.140327  22.509277  ...     1      18.571834      9.801731   \n",
       "\n",
       "   ewm_u_in_corr  rolling_10_mean  rolling_10_max  rolling_10_std  \\\n",
       "0            0.0         0.083334        0.083334        0.000000   \n",
       "1            1.0         9.233188       18.383041       12.939847   \n",
       "2            1.0        13.658551       22.509277       11.936136   \n",
       "3            1.0        15.946119       22.808823       10.766279   \n",
       "4            1.0        17.828065       25.355850       10.229525   \n",
       "\n",
       "   expand_mean  expand_max  expand_std  \n",
       "0     0.000000    0.000000    0.000000  \n",
       "1     9.233188   18.383041   12.939847  \n",
       "2    13.658551   22.509277   11.936136  \n",
       "3    15.946119   22.808823   10.766279  \n",
       "4    17.828065   25.355850   10.229525  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>area</th>\n",
       "      <th>u_in_cumsum</th>\n",
       "      <th>u_in_lag2</th>\n",
       "      <th>u_in_lag4</th>\n",
       "      <th>R_20</th>\n",
       "      <th>...</th>\n",
       "      <th>C_50</th>\n",
       "      <th>ewm_u_in_mean</th>\n",
       "      <th>ewm_u_in_std</th>\n",
       "      <th>ewm_u_in_corr</th>\n",
       "      <th>rolling_10_mean</th>\n",
       "      <th>rolling_10_max</th>\n",
       "      <th>rolling_10_std</th>\n",
       "      <th>expand_mean</th>\n",
       "      <th>expand_max</th>\n",
       "      <th>expand_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0</td>\n",
       "      <td>0.239758</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.887697</td>\n",
       "      <td>5.313940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.757523</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>5.313940</td>\n",
       "      <td>3.757523</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>5.313940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>0</td>\n",
       "      <td>1.174935</td>\n",
       "      <td>22.166721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.727061</td>\n",
       "      <td>7.319352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.388907</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>7.326652</td>\n",
       "      <td>7.388907</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>7.326652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>0</td>\n",
       "      <td>3.207788</td>\n",
       "      <td>43.397331</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11.461619</td>\n",
       "      <td>9.121700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.849333</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>9.147936</td>\n",
       "      <td>10.849333</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>9.147936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>26.320955</td>\n",
       "      <td>0</td>\n",
       "      <td>6.567489</td>\n",
       "      <td>69.718285</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>14.859053</td>\n",
       "      <td>10.439696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.943657</td>\n",
       "      <td>26.320955</td>\n",
       "      <td>10.518449</td>\n",
       "      <td>13.943657</td>\n",
       "      <td>26.320955</td>\n",
       "      <td>10.518449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  time_step       u_in  u_out      area  u_in_cumsum  \\\n",
       "0   1          0   0.000000   0.000000      0  0.000000     0.000000   \n",
       "1   2          0   0.031904   7.515046      0  0.239758     7.515046   \n",
       "2   3          0   0.063827  14.651675      0  1.174935    22.166721   \n",
       "3   4          0   0.095751  21.230610      0  3.207788    43.397331   \n",
       "4   5          0   0.127644  26.320955      0  6.567489    69.718285   \n",
       "\n",
       "   u_in_lag2  u_in_lag4  R_20  ...  C_50  ewm_u_in_mean  ewm_u_in_std  \\\n",
       "0   0.000000        0.0     0  ...     0       0.000000      0.000000   \n",
       "1   0.000000        0.0     0  ...     0       3.887697      5.313940   \n",
       "2   0.000000        0.0     0  ...     0       7.727061      7.319352   \n",
       "3   7.515046        0.0     0  ...     0      11.461619      9.121700   \n",
       "4  14.651675        0.0     0  ...     0      14.859053     10.439696   \n",
       "\n",
       "   ewm_u_in_corr  rolling_10_mean  rolling_10_max  rolling_10_std  \\\n",
       "0            0.0         0.000000        0.000000        0.000000   \n",
       "1            1.0         3.757523        7.515046        5.313940   \n",
       "2            1.0         7.388907       14.651675        7.326652   \n",
       "3            1.0        10.849333       21.230610        9.147936   \n",
       "4            1.0        13.943657       26.320955       10.518449   \n",
       "\n",
       "   expand_mean  expand_max  expand_std  \n",
       "0     0.000000    0.000000    0.000000  \n",
       "1     3.757523    7.515046    5.313940  \n",
       "2     7.388907   14.651675    7.326652  \n",
       "3    10.849333   21.230610    9.147936  \n",
       "4    13.943657   26.320955   10.518449  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train.head()), display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T02:34:42.570393Z",
     "start_time": "2021-10-19T02:34:42.557587Z"
    }
   },
   "outputs": [],
   "source": [
    "if config.use_lr_finder:\n",
    "    # data\n",
    "    rs = RobustScaler(quantile_range=(config.low_q, config.high_q), unit_variance=config.unit_var)\n",
    "    X_train = rs.fit_transform(train[feature_cols])\n",
    "    X_train = X_train.reshape(-1, 80, len(feature_cols))\n",
    "    y_train = train['pressure'].values.reshape(-1, 80)\n",
    "    w_train = (1 - train['u_out']).values.reshape(-1, 80)\n",
    "    train_dt = dataset.LR_VPP(X_train, y_train, w_train)\n",
    "    train_loader = DataLoader(train_dt,\n",
    "                              batch_size=config.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=config.num_workers, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T02:34:42.588467Z",
     "start_time": "2021-10-19T02:34:42.571563Z"
    }
   },
   "outputs": [],
   "source": [
    "if config.use_lr_finder:\n",
    "    # model\n",
    "    model = models.Model(len(feature_cols),config)\n",
    "    model.to(config.device)\n",
    "    if len(config.gpu) > 1:\n",
    "        model = DataParallel(model)\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-6, eps=1e-08, weight_decay=config.weight_decay, amsgrad=False)\n",
    "    criterion = loss.cal_mae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T02:34:42.601445Z",
     "start_time": "2021-10-19T02:34:42.589239Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if config.use_lr_finder:\n",
    "    lr_finder = lrfinder.LRFinder(model, optimizer, criterion, config.device)\n",
    "    lrs, losses = lr_finder.range_test(train_loader, end_lr=10, num_iter=100, smooth_f=0.05, diverge_th=5)    \n",
    "    lrfinder.plot_lr_finder(lrs, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T02:34:42.614713Z",
     "start_time": "2021-10-19T02:34:42.602193Z"
    }
   },
   "outputs": [],
   "source": [
    "if config.use_lr_finder:\n",
    "    del model, optimizer, criterion, train_dt, train_loader, lr_finder\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T04:20:11.186074Z",
     "start_time": "2021-10-19T02:35:32.792192Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  0\n",
      "Unsctrict scale - leakage..\n",
      "training data samples, val data samples:  (60515, 80, 22) (14935, 80, 22)\n",
      "Model Size: 5696501\n",
      "Epoch:  0\n",
      "loss:  2.5649, val_loss 1.3122, val_score 1.3134, best_val_score 1.3134, lr 0.00100 --- use 19.688s\n",
      "Epoch:  1\n",
      "loss:  1.2061, val_loss 1.1480, val_score 1.1485, best_val_score 1.1485, lr 0.00100 --- use 19.587s\n",
      "Epoch:  2\n",
      "loss:  1.0629, val_loss 0.9692, val_score 0.9702, best_val_score 0.9702, lr 0.00100 --- use 19.730s\n",
      "Epoch:  3\n",
      "loss:  0.9511, val_loss 0.8289, val_score 0.8289, best_val_score 0.8289, lr 0.00100 --- use 19.860s\n",
      "Epoch:  4\n",
      "loss:  0.8102, val_loss 0.6947, val_score 0.6953, best_val_score 0.6953, lr 0.00100 --- use 19.891s\n",
      "Epoch:  5\n",
      "loss:  0.6864, val_loss 0.6578, val_score 0.6579, best_val_score 0.6579, lr 0.00100 --- use 19.843s\n",
      "Epoch:  6\n",
      "loss:  0.6521, val_loss 0.6273, val_score 0.6278, best_val_score 0.6278, lr 0.00100 --- use 19.772s\n",
      "Epoch:  7\n",
      "loss:  0.6065, val_loss 0.6030, val_score 0.6034, best_val_score 0.6034, lr 0.00100 --- use 19.833s\n",
      "Epoch:  8\n",
      "loss:  0.5896, val_loss 0.6109, val_score 0.6106, best_val_score 0.6034, lr 0.00100 --- use 19.867s\n",
      "Epoch:  9\n",
      "loss:  0.5798, val_loss 0.5202, val_score 0.5202, best_val_score 0.5202, lr 0.00100 --- use 19.738s\n",
      "Epoch:  10\n",
      "loss:  0.5443, val_loss 0.4965, val_score 0.4966, best_val_score 0.4966, lr 0.00100 --- use 19.749s\n",
      "Epoch:  11\n",
      "loss:  0.4993, val_loss 0.5049, val_score 0.5050, best_val_score 0.4966, lr 0.00100 --- use 19.516s\n",
      "Epoch:  12\n",
      "loss:  0.5058, val_loss 0.5173, val_score 0.5174, best_val_score 0.4966, lr 0.00100 --- use 19.557s\n",
      "Epoch:  13\n",
      "loss:  0.4773, val_loss 0.5130, val_score 0.5129, best_val_score 0.4966, lr 0.00100 --- use 19.629s\n",
      "Epoch:  14\n",
      "loss:  0.4678, val_loss 0.4686, val_score 0.4687, best_val_score 0.4687, lr 0.00100 --- use 19.677s\n",
      "Epoch:  15\n",
      "loss:  0.4645, val_loss 0.4646, val_score 0.4648, best_val_score 0.4648, lr 0.00100 --- use 19.943s\n",
      "Epoch:  16\n",
      "loss:  0.4691, val_loss 0.4741, val_score 0.4742, best_val_score 0.4648, lr 0.00100 --- use 19.663s\n",
      "Epoch:  17\n",
      "loss:  0.4897, val_loss 0.5305, val_score 0.5303, best_val_score 0.4648, lr 0.00100 --- use 19.623s\n",
      "Epoch:  18\n",
      "loss:  0.4539, val_loss 0.4247, val_score 0.4245, best_val_score 0.4245, lr 0.00100 --- use 19.784s\n",
      "Epoch:  19\n",
      "loss:  0.4275, val_loss 0.4422, val_score 0.4420, best_val_score 0.4245, lr 0.00100 --- use 19.576s\n",
      "Epoch:  20\n",
      "loss:  0.4168, val_loss 0.4118, val_score 0.4115, best_val_score 0.4115, lr 0.00100 --- use 19.709s\n",
      "Epoch:  21\n",
      "loss:  0.4074, val_loss 0.4206, val_score 0.4203, best_val_score 0.4115, lr 0.00100 --- use 19.634s\n",
      "Epoch:  22\n",
      "loss:  0.4181, val_loss 0.4852, val_score 0.4852, best_val_score 0.4115, lr 0.00100 --- use 19.758s\n",
      "Epoch:  23\n",
      "loss:  0.4261, val_loss 0.4549, val_score 0.4544, best_val_score 0.4115, lr 0.00100 --- use 19.579s\n",
      "Epoch:  24\n",
      "loss:  0.4061, val_loss 0.3966, val_score 0.3964, best_val_score 0.3964, lr 0.00100 --- use 19.672s\n",
      "Epoch:  25\n",
      "loss:  0.3829, val_loss 0.3801, val_score 0.3799, best_val_score 0.3799, lr 0.00100 --- use 19.698s\n",
      "Epoch:  26\n",
      "loss:  0.3909, val_loss 0.4274, val_score 0.4275, best_val_score 0.3799, lr 0.00100 --- use 19.686s\n",
      "Epoch:  27\n",
      "loss:  0.3898, val_loss 0.4583, val_score 0.4582, best_val_score 0.3799, lr 0.00100 --- use 19.757s\n",
      "Epoch:  28\n",
      "loss:  0.3980, val_loss 0.4023, val_score 0.4021, best_val_score 0.3799, lr 0.00100 --- use 19.683s\n",
      "Epoch:  29\n",
      "loss:  0.4076, val_loss 0.4159, val_score 0.4157, best_val_score 0.3799, lr 0.00100 --- use 19.649s\n",
      "Epoch:  30\n",
      "loss:  0.3792, val_loss 0.4002, val_score 0.4002, best_val_score 0.3799, lr 0.00100 --- use 19.663s\n",
      "Epoch:  31\n",
      "loss:  0.3630, val_loss 0.3747, val_score 0.3745, best_val_score 0.3745, lr 0.00100 --- use 19.868s\n",
      "Epoch:  32\n",
      "loss:  0.3455, val_loss 0.3490, val_score 0.3490, best_val_score 0.3490, lr 0.00100 --- use 19.797s\n",
      "Epoch:  33\n",
      "loss:  0.3809, val_loss 0.3808, val_score 0.3809, best_val_score 0.3490, lr 0.00100 --- use 19.790s\n",
      "Epoch:  34\n",
      "loss:  0.3552, val_loss 0.3596, val_score 0.3596, best_val_score 0.3490, lr 0.00100 --- use 19.576s\n",
      "Epoch:  35\n",
      "loss:  0.3498, val_loss 0.3743, val_score 0.3741, best_val_score 0.3490, lr 0.00100 --- use 19.764s\n",
      "Epoch:  36\n",
      "loss:  0.3693, val_loss 0.3654, val_score 0.3652, best_val_score 0.3490, lr 0.00100 --- use 19.649s\n",
      "Epoch:  37\n",
      "loss:  0.3682, val_loss 0.3918, val_score 0.3917, best_val_score 0.3490, lr 0.00100 --- use 19.616s\n",
      "Epoch:  38\n",
      "loss:  0.3606, val_loss 0.3675, val_score 0.3677, best_val_score 0.3490, lr 0.00100 --- use 19.856s\n",
      "Epoch:  39\n",
      "loss:  0.3331, val_loss 0.3743, val_score 0.3744, best_val_score 0.3490, lr 0.00100 --- use 19.728s\n",
      "Epoch:  40\n",
      "loss:  0.3380, val_loss 0.3577, val_score 0.3579, best_val_score 0.3490, lr 0.00100 --- use 19.683s\n",
      "Epoch:  41\n",
      "loss:  0.3332, val_loss 0.3309, val_score 0.3307, best_val_score 0.3307, lr 0.00100 --- use 19.751s\n",
      "Epoch:  42\n",
      "loss:  0.3202, val_loss 0.3790, val_score 0.3790, best_val_score 0.3307, lr 0.00100 --- use 19.619s\n",
      "Epoch:  43\n",
      "loss:  0.3360, val_loss 0.3658, val_score 0.3660, best_val_score 0.3307, lr 0.00100 --- use 19.721s\n",
      "Epoch:  44\n",
      "loss:  0.3496, val_loss 0.3514, val_score 0.3512, best_val_score 0.3307, lr 0.00100 --- use 19.714s\n",
      "Epoch:  45\n",
      "loss:  0.3408, val_loss 0.3473, val_score 0.3473, best_val_score 0.3307, lr 0.00100 --- use 19.729s\n",
      "Epoch:  46\n",
      "loss:  0.3171, val_loss 0.3104, val_score 0.3106, best_val_score 0.3106, lr 0.00100 --- use 19.870s\n",
      "Epoch:  47\n",
      "loss:  0.3218, val_loss 0.3205, val_score 0.3206, best_val_score 0.3106, lr 0.00100 --- use 19.635s\n",
      "Epoch:  48\n",
      "loss:  0.3175, val_loss 0.3633, val_score 0.3633, best_val_score 0.3106, lr 0.00100 --- use 19.699s\n",
      "Epoch:  49\n",
      "loss:  0.3168, val_loss 0.3157, val_score 0.3156, best_val_score 0.3106, lr 0.00100 --- use 19.733s\n",
      "Epoch:  50\n",
      "loss:  0.2977, val_loss 0.3085, val_score 0.3085, best_val_score 0.3085, lr 0.00100 --- use 19.938s\n",
      "Epoch:  51\n",
      "loss:  0.3109, val_loss 0.3115, val_score 0.3117, best_val_score 0.3085, lr 0.00100 --- use 19.843s\n",
      "Epoch:  52\n",
      "loss:  0.3060, val_loss 0.3152, val_score 0.3152, best_val_score 0.3085, lr 0.00100 --- use 19.667s\n",
      "Epoch:  53\n",
      "loss:  0.3147, val_loss 0.3180, val_score 0.3177, best_val_score 0.3085, lr 0.00100 --- use 19.773s\n",
      "Epoch:  54\n",
      "loss:  0.2988, val_loss 0.3824, val_score 0.3822, best_val_score 0.3085, lr 0.00100 --- use 19.667s\n",
      "Epoch:  55\n",
      "loss:  0.3315, val_loss 0.3233, val_score 0.3234, best_val_score 0.3085, lr 0.00100 --- use 19.765s\n",
      "Epoch:  56\n",
      "loss:  0.3227, val_loss 0.3398, val_score 0.3400, best_val_score 0.3085, lr 0.00100 --- use 19.922s\n",
      "Epoch:  57\n",
      "loss:  0.2966, val_loss 0.3067, val_score 0.3067, best_val_score 0.3067, lr 0.00100 --- use 19.853s\n",
      "Epoch:  58\n",
      "loss:  0.3119, val_loss 0.3817, val_score 0.3819, best_val_score 0.3067, lr 0.00100 --- use 19.705s\n",
      "Epoch:  59\n",
      "loss:  0.3045, val_loss 0.3163, val_score 0.3164, best_val_score 0.3067, lr 0.00100 --- use 19.870s\n",
      "Epoch:  60\n",
      "loss:  0.3050, val_loss 0.2919, val_score 0.2917, best_val_score 0.2917, lr 0.00100 --- use 19.859s\n",
      "Epoch:  61\n",
      "loss:  0.2816, val_loss 0.2887, val_score 0.2890, best_val_score 0.2890, lr 0.00100 --- use 19.891s\n",
      "Epoch:  62\n",
      "loss:  0.2804, val_loss 0.2829, val_score 0.2830, best_val_score 0.2830, lr 0.00100 --- use 19.921s\n",
      "Epoch:  63\n",
      "loss:  0.2837, val_loss 0.3411, val_score 0.3414, best_val_score 0.2830, lr 0.00100 --- use 19.654s\n",
      "Epoch:  64\n",
      "loss:  0.2986, val_loss 0.3077, val_score 0.3078, best_val_score 0.2830, lr 0.00100 --- use 19.693s\n",
      "Epoch:  65\n",
      "loss:  0.2927, val_loss 0.2837, val_score 0.2836, best_val_score 0.2830, lr 0.00100 --- use 19.759s\n",
      "Epoch:  66\n",
      "loss:  0.2687, val_loss 0.3005, val_score 0.3009, best_val_score 0.2830, lr 0.00100 --- use 19.820s\n",
      "Epoch:  67\n",
      "loss:  0.2838, val_loss 0.2941, val_score 0.2941, best_val_score 0.2830, lr 0.00100 --- use 19.697s\n",
      "Epoch:  68\n",
      "loss:  0.2856, val_loss 0.2904, val_score 0.2905, best_val_score 0.2830, lr 0.00100 --- use 19.674s\n",
      "Epoch:  69\n",
      "loss:  0.2719, val_loss 0.2764, val_score 0.2766, best_val_score 0.2766, lr 0.00100 --- use 19.849s\n",
      "Epoch:  70\n",
      "loss:  0.2595, val_loss 0.2641, val_score 0.2641, best_val_score 0.2641, lr 0.00100 --- use 19.827s\n",
      "Epoch:  71\n",
      "loss:  0.2646, val_loss 0.2782, val_score 0.2784, best_val_score 0.2641, lr 0.00100 --- use 19.860s\n",
      "Epoch:  72\n",
      "loss:  0.2644, val_loss 0.3325, val_score 0.3327, best_val_score 0.2641, lr 0.00100 --- use 19.865s\n",
      "Epoch:  73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.3005, val_loss 0.3250, val_score 0.3256, best_val_score 0.2641, lr 0.00100 --- use 19.728s\n",
      "Epoch:  74\n",
      "loss:  0.2840, val_loss 0.3210, val_score 0.3211, best_val_score 0.2641, lr 0.00100 --- use 19.672s\n",
      "Epoch:  75\n",
      "loss:  0.2900, val_loss 0.3091, val_score 0.3092, best_val_score 0.2641, lr 0.00100 --- use 19.745s\n",
      "Epoch:  76\n",
      "loss:  0.2829, val_loss 0.2878, val_score 0.2879, best_val_score 0.2641, lr 0.00100 --- use 19.728s\n",
      "Epoch:  77\n",
      "loss:  0.2739, val_loss 0.2682, val_score 0.2682, best_val_score 0.2641, lr 0.00100 --- use 19.664s\n",
      "Epoch:  78\n",
      "loss:  0.2510, val_loss 0.2569, val_score 0.2570, best_val_score 0.2570, lr 0.00100 --- use 19.834s\n",
      "Epoch:  79\n",
      "loss:  0.2492, val_loss 0.2503, val_score 0.2504, best_val_score 0.2504, lr 0.00100 --- use 19.835s\n",
      "Epoch:  80\n",
      "loss:  0.2555, val_loss 0.2663, val_score 0.2666, best_val_score 0.2504, lr 0.00100 --- use 19.902s\n",
      "Epoch:  81\n",
      "loss:  0.2663, val_loss 0.3157, val_score 0.3158, best_val_score 0.2504, lr 0.00100 --- use 19.715s\n",
      "Epoch:  82\n",
      "loss:  0.2949, val_loss 0.3056, val_score 0.3059, best_val_score 0.2504, lr 0.00100 --- use 19.790s\n",
      "Epoch:  83\n",
      "loss:  0.2763, val_loss 0.2904, val_score 0.2905, best_val_score 0.2504, lr 0.00100 --- use 19.801s\n",
      "Epoch:  84\n",
      "loss:  0.2761, val_loss 0.2915, val_score 0.2915, best_val_score 0.2504, lr 0.00100 --- use 19.771s\n",
      "Epoch:  85\n",
      "loss:  0.2713, val_loss 0.2919, val_score 0.2918, best_val_score 0.2504, lr 0.00100 --- use 19.768s\n",
      "Epoch:  86\n",
      "loss:  0.2817, val_loss 0.2854, val_score 0.2855, best_val_score 0.2504, lr 0.00100 --- use 19.747s\n",
      "Epoch:  87\n",
      "loss:  0.2629, val_loss 0.2785, val_score 0.2784, best_val_score 0.2504, lr 0.00100 --- use 19.779s\n",
      "Epoch:  88\n",
      "loss:  0.2661, val_loss 0.2664, val_score 0.2664, best_val_score 0.2504, lr 0.00100 --- use 19.755s\n",
      "Epoch:  89\n",
      "loss:  0.2477, val_loss 0.2528, val_score 0.2526, best_val_score 0.2504, lr 0.00100 --- use 19.711s\n",
      "Epoch:  90\n",
      "Epoch    91: reducing learning rate of group 0 to 5.0000e-04.\n",
      "loss:  0.2526, val_loss 0.2810, val_score 0.2812, best_val_score 0.2504, lr 0.00100 --- use 19.851s\n",
      "Epoch:  91\n",
      "loss:  0.2329, val_loss 0.2410, val_score 0.2412, best_val_score 0.2412, lr 0.00050 --- use 19.789s\n",
      "Epoch:  92\n",
      "loss:  0.2185, val_loss 0.2407, val_score 0.2408, best_val_score 0.2408, lr 0.00050 --- use 19.828s\n",
      "Epoch:  93\n",
      "loss:  0.2290, val_loss 0.2441, val_score 0.2442, best_val_score 0.2408, lr 0.00050 --- use 19.782s\n",
      "Epoch:  94\n",
      "loss:  0.2230, val_loss 0.2474, val_score 0.2475, best_val_score 0.2408, lr 0.00050 --- use 19.691s\n",
      "Epoch:  95\n",
      "loss:  0.2258, val_loss 0.2516, val_score 0.2517, best_val_score 0.2408, lr 0.00050 --- use 19.922s\n",
      "Epoch:  96\n",
      "loss:  0.2293, val_loss 0.2386, val_score 0.2387, best_val_score 0.2387, lr 0.00050 --- use 19.867s\n",
      "Epoch:  97\n",
      "loss:  0.2281, val_loss 0.2484, val_score 0.2484, best_val_score 0.2387, lr 0.00050 --- use 19.764s\n",
      "Epoch:  98\n",
      "loss:  0.2217, val_loss 0.2340, val_score 0.2341, best_val_score 0.2341, lr 0.00050 --- use 19.941s\n",
      "Epoch:  99\n",
      "loss:  0.2208, val_loss 0.2430, val_score 0.2432, best_val_score 0.2341, lr 0.00050 --- use 19.702s\n",
      "Epoch:  100\n",
      "loss:  0.2142, val_loss 0.2272, val_score 0.2272, best_val_score 0.2272, lr 0.00050 --- use 19.886s\n",
      "Epoch:  101\n",
      "loss:  0.2059, val_loss 0.2260, val_score 0.2262, best_val_score 0.2262, lr 0.00050 --- use 19.818s\n",
      "Epoch:  102\n",
      "loss:  0.2059, val_loss 0.2321, val_score 0.2322, best_val_score 0.2262, lr 0.00050 --- use 19.715s\n",
      "Epoch:  103\n",
      "loss:  0.2116, val_loss 0.2339, val_score 0.2340, best_val_score 0.2262, lr 0.00050 --- use 19.833s\n",
      "Epoch:  104\n",
      "loss:  0.2186, val_loss 0.2396, val_score 0.2396, best_val_score 0.2262, lr 0.00050 --- use 19.678s\n",
      "Epoch:  105\n",
      "loss:  0.2169, val_loss 0.2433, val_score 0.2434, best_val_score 0.2262, lr 0.00050 --- use 19.781s\n",
      "Epoch:  106\n",
      "loss:  0.2160, val_loss 0.2362, val_score 0.2362, best_val_score 0.2262, lr 0.00050 --- use 19.719s\n",
      "Epoch:  107\n",
      "loss:  0.2106, val_loss 0.2234, val_score 0.2233, best_val_score 0.2233, lr 0.00050 --- use 19.912s\n",
      "Epoch:  108\n",
      "loss:  0.1994, val_loss 0.2181, val_score 0.2181, best_val_score 0.2181, lr 0.00050 --- use 20.042s\n",
      "Epoch:  109\n",
      "loss:  0.1989, val_loss 0.2252, val_score 0.2253, best_val_score 0.2181, lr 0.00050 --- use 19.743s\n",
      "Epoch:  110\n",
      "loss:  0.1978, val_loss 0.2186, val_score 0.2187, best_val_score 0.2181, lr 0.00050 --- use 19.779s\n",
      "Epoch:  111\n",
      "loss:  0.1967, val_loss 0.2180, val_score 0.2182, best_val_score 0.2181, lr 0.00050 --- use 19.791s\n",
      "Epoch:  112\n",
      "loss:  0.1939, val_loss 0.2175, val_score 0.2175, best_val_score 0.2175, lr 0.00050 --- use 19.907s\n",
      "Epoch:  113\n",
      "loss:  0.2041, val_loss 0.2356, val_score 0.2354, best_val_score 0.2175, lr 0.00050 --- use 19.703s\n",
      "Epoch:  114\n",
      "loss:  0.2087, val_loss 0.2252, val_score 0.2253, best_val_score 0.2175, lr 0.00050 --- use 19.710s\n",
      "Epoch:  115\n",
      "loss:  0.2095, val_loss 0.2399, val_score 0.2399, best_val_score 0.2175, lr 0.00050 --- use 19.801s\n",
      "Epoch:  116\n",
      "loss:  0.2116, val_loss 0.2285, val_score 0.2286, best_val_score 0.2175, lr 0.00050 --- use 19.721s\n",
      "Epoch:  117\n",
      "loss:  0.2078, val_loss 0.2381, val_score 0.2381, best_val_score 0.2175, lr 0.00050 --- use 19.657s\n",
      "Epoch:  118\n",
      "loss:  0.2134, val_loss 0.2384, val_score 0.2385, best_val_score 0.2175, lr 0.00050 --- use 19.979s\n",
      "Epoch:  119\n",
      "loss:  0.2043, val_loss 0.2341, val_score 0.2343, best_val_score 0.2175, lr 0.00050 --- use 19.807s\n",
      "Epoch:  120\n",
      "loss:  0.2062, val_loss 0.2307, val_score 0.2307, best_val_score 0.2175, lr 0.00050 --- use 19.747s\n",
      "Epoch:  121\n",
      "loss:  0.2101, val_loss 0.2245, val_score 0.2247, best_val_score 0.2175, lr 0.00050 --- use 19.779s\n",
      "Epoch:  122\n",
      "loss:  0.2058, val_loss 0.2288, val_score 0.2288, best_val_score 0.2175, lr 0.00050 --- use 19.759s\n",
      "Epoch:  123\n",
      "loss:  0.1934, val_loss 0.2148, val_score 0.2149, best_val_score 0.2149, lr 0.00050 --- use 19.927s\n",
      "Epoch:  124\n",
      "loss:  0.1875, val_loss 0.2140, val_score 0.2141, best_val_score 0.2141, lr 0.00050 --- use 19.786s\n",
      "Epoch:  125\n",
      "loss:  0.1895, val_loss 0.2228, val_score 0.2230, best_val_score 0.2141, lr 0.00050 --- use 19.793s\n",
      "Epoch:  126\n",
      "loss:  0.2046, val_loss 0.2387, val_score 0.2390, best_val_score 0.2141, lr 0.00050 --- use 19.941s\n",
      "Epoch:  127\n",
      "loss:  0.2128, val_loss 0.2307, val_score 0.2309, best_val_score 0.2141, lr 0.00050 --- use 19.782s\n",
      "Epoch:  128\n",
      "loss:  0.2053, val_loss 0.2308, val_score 0.2309, best_val_score 0.2141, lr 0.00050 --- use 19.758s\n",
      "Epoch:  129\n",
      "loss:  0.2087, val_loss 0.2333, val_score 0.2333, best_val_score 0.2141, lr 0.00050 --- use 19.740s\n",
      "Epoch:  130\n",
      "loss:  0.1966, val_loss 0.2169, val_score 0.2169, best_val_score 0.2141, lr 0.00050 --- use 19.714s\n",
      "Epoch:  131\n",
      "loss:  0.1906, val_loss 0.2277, val_score 0.2276, best_val_score 0.2141, lr 0.00050 --- use 19.757s\n",
      "Epoch:  132\n",
      "loss:  0.1965, val_loss 0.2193, val_score 0.2193, best_val_score 0.2141, lr 0.00050 --- use 19.742s\n",
      "Epoch:  133\n",
      "loss:  0.1828, val_loss 0.2189, val_score 0.2191, best_val_score 0.2141, lr 0.00050 --- use 19.723s\n",
      "Epoch:  134\n",
      "loss:  0.1843, val_loss 0.2211, val_score 0.2212, best_val_score 0.2141, lr 0.00050 --- use 19.755s\n",
      "Epoch:  135\n",
      "Epoch   136: reducing learning rate of group 0 to 2.5000e-04.\n",
      "loss:  0.1935, val_loss 0.2470, val_score 0.2471, best_val_score 0.2141, lr 0.00050 --- use 19.723s\n",
      "Epoch:  136\n",
      "loss:  0.1867, val_loss 0.2154, val_score 0.2152, best_val_score 0.2141, lr 0.00025 --- use 19.769s\n",
      "Epoch:  137\n",
      "loss:  0.1828, val_loss 0.2168, val_score 0.2167, best_val_score 0.2141, lr 0.00025 --- use 19.781s\n",
      "Epoch:  138\n",
      "loss:  0.1811, val_loss 0.2099, val_score 0.2100, best_val_score 0.2100, lr 0.00025 --- use 19.867s\n",
      "Epoch:  139\n",
      "loss:  0.1789, val_loss 0.2110, val_score 0.2110, best_val_score 0.2100, lr 0.00025 --- use 19.710s\n",
      "Epoch:  140\n",
      "loss:  0.1807, val_loss 0.2131, val_score 0.2131, best_val_score 0.2100, lr 0.00025 --- use 19.716s\n",
      "Epoch:  141\n",
      "loss:  0.1773, val_loss 0.2064, val_score 0.2064, best_val_score 0.2064, lr 0.00025 --- use 19.955s\n",
      "Epoch:  142\n",
      "loss:  0.1741, val_loss 0.2110, val_score 0.2110, best_val_score 0.2064, lr 0.00025 --- use 19.755s\n",
      "Epoch:  143\n",
      "loss:  0.1780, val_loss 0.2129, val_score 0.2128, best_val_score 0.2064, lr 0.00025 --- use 19.655s\n",
      "Epoch:  144\n",
      "loss:  0.1788, val_loss 0.2155, val_score 0.2156, best_val_score 0.2064, lr 0.00025 --- use 19.740s\n",
      "Epoch:  145\n",
      "loss:  0.1761, val_loss 0.2089, val_score 0.2090, best_val_score 0.2064, lr 0.00025 --- use 19.669s\n",
      "Epoch:  146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.1743, val_loss 0.2099, val_score 0.2099, best_val_score 0.2064, lr 0.00025 --- use 19.722s\n",
      "Epoch:  147\n",
      "loss:  0.1727, val_loss 0.2094, val_score 0.2093, best_val_score 0.2064, lr 0.00025 --- use 19.785s\n",
      "Epoch:  148\n",
      "loss:  0.1732, val_loss 0.2093, val_score 0.2094, best_val_score 0.2064, lr 0.00025 --- use 19.662s\n",
      "Epoch:  149\n",
      "loss:  0.1710, val_loss 0.2078, val_score 0.2080, best_val_score 0.2064, lr 0.00025 --- use 19.709s\n",
      "Epoch:  150\n",
      "loss:  0.1718, val_loss 0.2061, val_score 0.2064, best_val_score 0.2064, lr 0.00025 --- use 19.870s\n",
      "Epoch:  151\n",
      "loss:  0.1731, val_loss 0.2072, val_score 0.2074, best_val_score 0.2064, lr 0.00025 --- use 19.801s\n",
      "Epoch:  152\n",
      "loss:  0.1707, val_loss 0.2054, val_score 0.2055, best_val_score 0.2055, lr 0.00025 --- use 19.903s\n",
      "Epoch:  153\n",
      "loss:  0.1675, val_loss 0.2057, val_score 0.2058, best_val_score 0.2055, lr 0.00025 --- use 19.670s\n",
      "Epoch:  154\n",
      "loss:  0.1714, val_loss 0.2089, val_score 0.2090, best_val_score 0.2055, lr 0.00025 --- use 19.757s\n",
      "Epoch:  155\n",
      "loss:  0.1684, val_loss 0.2060, val_score 0.2061, best_val_score 0.2055, lr 0.00025 --- use 19.708s\n",
      "Epoch:  156\n",
      "loss:  0.1692, val_loss 0.2119, val_score 0.2119, best_val_score 0.2055, lr 0.00025 --- use 19.707s\n",
      "Epoch:  157\n",
      "loss:  0.1659, val_loss 0.2059, val_score 0.2059, best_val_score 0.2055, lr 0.00025 --- use 19.917s\n",
      "Epoch:  158\n",
      "loss:  0.1637, val_loss 0.2046, val_score 0.2047, best_val_score 0.2047, lr 0.00025 --- use 19.911s\n",
      "Epoch:  159\n",
      "loss:  0.1649, val_loss 0.2058, val_score 0.2060, best_val_score 0.2047, lr 0.00025 --- use 19.699s\n",
      "Epoch:  160\n",
      "loss:  0.1662, val_loss 0.2077, val_score 0.2078, best_val_score 0.2047, lr 0.00025 --- use 19.763s\n",
      "Epoch:  161\n",
      "loss:  0.1630, val_loss 0.2009, val_score 0.2011, best_val_score 0.2011, lr 0.00025 --- use 19.857s\n",
      "Epoch:  162\n",
      "loss:  0.1623, val_loss 0.2045, val_score 0.2047, best_val_score 0.2011, lr 0.00025 --- use 19.678s\n",
      "Epoch:  163\n",
      "loss:  0.1666, val_loss 0.2041, val_score 0.2041, best_val_score 0.2011, lr 0.00025 --- use 19.763s\n",
      "Epoch:  164\n",
      "loss:  0.1600, val_loss 0.2038, val_score 0.2038, best_val_score 0.2011, lr 0.00025 --- use 19.820s\n",
      "Epoch:  165\n",
      "loss:  0.1613, val_loss 0.2057, val_score 0.2060, best_val_score 0.2011, lr 0.00025 --- use 19.736s\n",
      "Epoch:  166\n",
      "loss:  0.1666, val_loss 0.2098, val_score 0.2097, best_val_score 0.2011, lr 0.00025 --- use 19.635s\n",
      "Epoch:  167\n",
      "loss:  0.1662, val_loss 0.2042, val_score 0.2043, best_val_score 0.2011, lr 0.00025 --- use 19.793s\n",
      "Epoch:  168\n",
      "loss:  0.1613, val_loss 0.2057, val_score 0.2058, best_val_score 0.2011, lr 0.00025 --- use 19.766s\n",
      "Epoch:  169\n",
      "loss:  0.1620, val_loss 0.2056, val_score 0.2058, best_val_score 0.2011, lr 0.00025 --- use 19.664s\n",
      "Epoch:  170\n",
      "loss:  0.1631, val_loss 0.2046, val_score 0.2048, best_val_score 0.2011, lr 0.00025 --- use 19.870s\n",
      "Epoch:  171\n",
      "loss:  0.1618, val_loss 0.2009, val_score 0.2011, best_val_score 0.2011, lr 0.00025 --- use 19.680s\n",
      "Epoch:  172\n",
      "Epoch   173: reducing learning rate of group 0 to 1.2500e-04.\n",
      "loss:  0.1606, val_loss 0.2021, val_score 0.2022, best_val_score 0.2011, lr 0.00025 --- use 19.707s\n",
      "Epoch:  173\n",
      "loss:  0.1556, val_loss 0.2005, val_score 0.2007, best_val_score 0.2007, lr 0.00013 --- use 19.964s\n",
      "Epoch:  174\n",
      "loss:  0.1535, val_loss 0.1996, val_score 0.1997, best_val_score 0.1997, lr 0.00013 --- use 19.861s\n",
      "Epoch:  175\n",
      "loss:  0.1535, val_loss 0.1995, val_score 0.1997, best_val_score 0.1997, lr 0.00013 --- use 19.932s\n",
      "Epoch:  176\n",
      "loss:  0.1522, val_loss 0.1981, val_score 0.1983, best_val_score 0.1983, lr 0.00013 --- use 19.806s\n",
      "Epoch:  177\n",
      "loss:  0.1509, val_loss 0.1997, val_score 0.1998, best_val_score 0.1983, lr 0.00013 --- use 19.739s\n",
      "Epoch:  178\n",
      "loss:  0.1529, val_loss 0.1989, val_score 0.1990, best_val_score 0.1983, lr 0.00013 --- use 19.697s\n",
      "Epoch:  179\n",
      "loss:  0.1522, val_loss 0.1986, val_score 0.1988, best_val_score 0.1983, lr 0.00013 --- use 19.669s\n",
      "Epoch:  180\n",
      "loss:  0.1520, val_loss 0.1981, val_score 0.1983, best_val_score 0.1983, lr 0.00013 --- use 19.682s\n",
      "Epoch:  181\n",
      "loss:  0.1507, val_loss 0.1989, val_score 0.1991, best_val_score 0.1983, lr 0.00013 --- use 19.768s\n",
      "Epoch:  182\n",
      "loss:  0.1504, val_loss 0.1993, val_score 0.1995, best_val_score 0.1983, lr 0.00013 --- use 19.778s\n",
      "Epoch:  183\n",
      "loss:  0.1511, val_loss 0.1980, val_score 0.1982, best_val_score 0.1982, lr 0.00013 --- use 19.906s\n",
      "Epoch:  184\n",
      "loss:  0.1494, val_loss 0.1981, val_score 0.1982, best_val_score 0.1982, lr 0.00013 --- use 19.864s\n",
      "Epoch:  185\n",
      "loss:  0.1491, val_loss 0.1978, val_score 0.1979, best_val_score 0.1979, lr 0.00013 --- use 19.851s\n",
      "Epoch:  186\n",
      "loss:  0.1497, val_loss 0.1972, val_score 0.1973, best_val_score 0.1973, lr 0.00013 --- use 19.752s\n",
      "Epoch:  187\n",
      "loss:  0.1485, val_loss 0.1975, val_score 0.1976, best_val_score 0.1973, lr 0.00013 --- use 19.634s\n",
      "Epoch:  188\n",
      "loss:  0.1486, val_loss 0.1983, val_score 0.1984, best_val_score 0.1973, lr 0.00013 --- use 19.588s\n",
      "Epoch:  189\n",
      "loss:  0.1482, val_loss 0.1973, val_score 0.1975, best_val_score 0.1973, lr 0.00013 --- use 19.699s\n",
      "Epoch:  190\n",
      "loss:  0.1476, val_loss 0.1990, val_score 0.1991, best_val_score 0.1973, lr 0.00013 --- use 19.742s\n",
      "Epoch:  191\n",
      "loss:  0.1477, val_loss 0.1981, val_score 0.1982, best_val_score 0.1973, lr 0.00013 --- use 19.616s\n",
      "Epoch:  192\n",
      "loss:  0.1477, val_loss 0.1975, val_score 0.1977, best_val_score 0.1973, lr 0.00013 --- use 19.620s\n",
      "Epoch:  193\n",
      "loss:  0.1464, val_loss 0.1970, val_score 0.1971, best_val_score 0.1971, lr 0.00013 --- use 19.995s\n",
      "Epoch:  194\n",
      "loss:  0.1460, val_loss 0.1977, val_score 0.1979, best_val_score 0.1971, lr 0.00013 --- use 19.711s\n",
      "Epoch:  195\n",
      "loss:  0.1462, val_loss 0.1963, val_score 0.1965, best_val_score 0.1965, lr 0.00013 --- use 19.828s\n",
      "Epoch:  196\n",
      "loss:  0.1455, val_loss 0.1972, val_score 0.1974, best_val_score 0.1965, lr 0.00013 --- use 19.723s\n",
      "Epoch:  197\n",
      "loss:  0.1447, val_loss 0.1967, val_score 0.1968, best_val_score 0.1965, lr 0.00013 --- use 19.668s\n",
      "Epoch:  198\n",
      "loss:  0.1449, val_loss 0.1979, val_score 0.1981, best_val_score 0.1965, lr 0.00013 --- use 19.763s\n",
      "Epoch:  199\n",
      "loss:  0.1450, val_loss 0.1970, val_score 0.1971, best_val_score 0.1965, lr 0.00013 --- use 19.610s\n",
      "Epoch:  200\n",
      "loss:  0.1434, val_loss 0.1970, val_score 0.1972, best_val_score 0.1965, lr 0.00013 --- use 19.628s\n",
      "Epoch:  201\n",
      "loss:  0.1447, val_loss 0.1957, val_score 0.1958, best_val_score 0.1958, lr 0.00013 --- use 19.758s\n",
      "Epoch:  202\n",
      "loss:  0.1435, val_loss 0.1966, val_score 0.1967, best_val_score 0.1958, lr 0.00013 --- use 19.703s\n",
      "Epoch:  203\n",
      "loss:  0.1437, val_loss 0.1967, val_score 0.1968, best_val_score 0.1958, lr 0.00013 --- use 19.833s\n",
      "Epoch:  204\n",
      "loss:  0.1446, val_loss 0.1959, val_score 0.1961, best_val_score 0.1958, lr 0.00013 --- use 19.671s\n",
      "Epoch:  205\n",
      "loss:  0.1434, val_loss 0.1969, val_score 0.1971, best_val_score 0.1958, lr 0.00013 --- use 19.686s\n",
      "Epoch:  206\n",
      "loss:  0.1425, val_loss 0.1967, val_score 0.1969, best_val_score 0.1958, lr 0.00013 --- use 19.644s\n",
      "Epoch:  207\n",
      "loss:  0.1412, val_loss 0.1960, val_score 0.1962, best_val_score 0.1958, lr 0.00013 --- use 19.647s\n",
      "Epoch:  208\n",
      "loss:  0.1421, val_loss 0.1970, val_score 0.1971, best_val_score 0.1958, lr 0.00013 --- use 19.860s\n",
      "Epoch:  209\n",
      "loss:  0.1421, val_loss 0.1972, val_score 0.1974, best_val_score 0.1958, lr 0.00013 --- use 19.722s\n",
      "Epoch:  210\n",
      "loss:  0.1429, val_loss 0.1965, val_score 0.1966, best_val_score 0.1958, lr 0.00013 --- use 19.558s\n",
      "Epoch:  211\n",
      "loss:  0.1420, val_loss 0.1964, val_score 0.1965, best_val_score 0.1958, lr 0.00013 --- use 19.742s\n",
      "Epoch:  212\n",
      "Epoch   213: reducing learning rate of group 0 to 6.2500e-05.\n",
      "loss:  0.1424, val_loss 0.1967, val_score 0.1968, best_val_score 0.1958, lr 0.00013 --- use 19.757s\n",
      "Epoch:  213\n",
      "loss:  0.1387, val_loss 0.1945, val_score 0.1947, best_val_score 0.1947, lr 0.00006 --- use 19.952s\n",
      "Epoch:  214\n",
      "loss:  0.1386, val_loss 0.1950, val_score 0.1953, best_val_score 0.1947, lr 0.00006 --- use 19.696s\n",
      "Epoch:  215\n",
      "loss:  0.1380, val_loss 0.1950, val_score 0.1953, best_val_score 0.1947, lr 0.00006 --- use 19.598s\n",
      "Epoch:  216\n",
      "loss:  0.1378, val_loss 0.1944, val_score 0.1945, best_val_score 0.1945, lr 0.00006 --- use 19.890s\n",
      "Epoch:  217\n",
      "loss:  0.1370, val_loss 0.1950, val_score 0.1952, best_val_score 0.1945, lr 0.00006 --- use 19.647s\n",
      "Epoch:  218\n",
      "loss:  0.1371, val_loss 0.1949, val_score 0.1951, best_val_score 0.1945, lr 0.00006 --- use 19.705s\n",
      "Epoch:  219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.1368, val_loss 0.1945, val_score 0.1946, best_val_score 0.1945, lr 0.00006 --- use 19.878s\n",
      "Epoch:  220\n",
      "loss:  0.1367, val_loss 0.1946, val_score 0.1948, best_val_score 0.1945, lr 0.00006 --- use 19.666s\n",
      "Epoch:  221\n",
      "loss:  0.1367, val_loss 0.1951, val_score 0.1953, best_val_score 0.1945, lr 0.00006 --- use 19.652s\n",
      "Epoch:  222\n",
      "loss:  0.1363, val_loss 0.1943, val_score 0.1945, best_val_score 0.1945, lr 0.00006 --- use 19.770s\n",
      "Epoch:  223\n",
      "loss:  0.1363, val_loss 0.1949, val_score 0.1950, best_val_score 0.1945, lr 0.00006 --- use 19.626s\n",
      "Epoch:  224\n",
      "loss:  0.1364, val_loss 0.1949, val_score 0.1950, best_val_score 0.1945, lr 0.00006 --- use 19.612s\n",
      "Epoch:  225\n",
      "loss:  0.1355, val_loss 0.1943, val_score 0.1945, best_val_score 0.1945, lr 0.00006 --- use 19.640s\n",
      "Epoch:  226\n",
      "loss:  0.1356, val_loss 0.1946, val_score 0.1948, best_val_score 0.1945, lr 0.00006 --- use 19.854s\n",
      "Epoch:  227\n",
      "loss:  0.1354, val_loss 0.1951, val_score 0.1952, best_val_score 0.1945, lr 0.00006 --- use 19.676s\n",
      "Epoch:  228\n",
      "loss:  0.1356, val_loss 0.1945, val_score 0.1947, best_val_score 0.1945, lr 0.00006 --- use 19.766s\n",
      "Epoch:  229\n",
      "loss:  0.1349, val_loss 0.1945, val_score 0.1947, best_val_score 0.1945, lr 0.00006 --- use 19.790s\n",
      "Epoch:  230\n",
      "loss:  0.1348, val_loss 0.1940, val_score 0.1942, best_val_score 0.1942, lr 0.00006 --- use 19.670s\n",
      "Epoch:  231\n",
      "loss:  0.1347, val_loss 0.1944, val_score 0.1946, best_val_score 0.1942, lr 0.00006 --- use 19.596s\n",
      "Epoch:  232\n",
      "loss:  0.1339, val_loss 0.1944, val_score 0.1946, best_val_score 0.1942, lr 0.00006 --- use 19.778s\n",
      "Epoch:  233\n",
      "loss:  0.1343, val_loss 0.1943, val_score 0.1945, best_val_score 0.1942, lr 0.00006 --- use 19.645s\n",
      "Epoch:  234\n",
      "loss:  0.1336, val_loss 0.1946, val_score 0.1947, best_val_score 0.1942, lr 0.00006 --- use 19.726s\n",
      "Epoch:  235\n",
      "loss:  0.1337, val_loss 0.1946, val_score 0.1948, best_val_score 0.1942, lr 0.00006 --- use 19.638s\n",
      "Epoch:  236\n",
      "loss:  0.1338, val_loss 0.1945, val_score 0.1947, best_val_score 0.1942, lr 0.00006 --- use 19.677s\n",
      "Epoch:  237\n",
      "loss:  0.1337, val_loss 0.1945, val_score 0.1947, best_val_score 0.1942, lr 0.00006 --- use 19.592s\n",
      "Epoch:  238\n",
      "loss:  0.1333, val_loss 0.1941, val_score 0.1943, best_val_score 0.1942, lr 0.00006 --- use 19.547s\n",
      "Epoch:  239\n",
      "loss:  0.1335, val_loss 0.1942, val_score 0.1944, best_val_score 0.1942, lr 0.00006 --- use 19.791s\n",
      "Epoch:  240\n",
      "loss:  0.1331, val_loss 0.1941, val_score 0.1942, best_val_score 0.1942, lr 0.00006 --- use 19.694s\n",
      "Epoch:  241\n",
      "Epoch   242: reducing learning rate of group 0 to 3.1250e-05.\n",
      "loss:  0.1329, val_loss 0.1940, val_score 0.1942, best_val_score 0.1942, lr 0.00006 --- use 19.686s\n",
      "Epoch:  242\n",
      "loss:  0.1315, val_loss 0.1939, val_score 0.1941, best_val_score 0.1941, lr 0.00003 --- use 20.020s\n",
      "Epoch:  243\n",
      "loss:  0.1315, val_loss 0.1937, val_score 0.1939, best_val_score 0.1939, lr 0.00003 --- use 19.824s\n",
      "Epoch:  244\n",
      "loss:  0.1310, val_loss 0.1938, val_score 0.1940, best_val_score 0.1939, lr 0.00003 --- use 19.746s\n",
      "Epoch:  245\n",
      "loss:  0.1312, val_loss 0.1937, val_score 0.1939, best_val_score 0.1939, lr 0.00003 --- use 19.860s\n",
      "Epoch:  246\n",
      "loss:  0.1309, val_loss 0.1936, val_score 0.1938, best_val_score 0.1938, lr 0.00003 --- use 19.872s\n",
      "Epoch:  247\n",
      "loss:  0.1306, val_loss 0.1937, val_score 0.1939, best_val_score 0.1938, lr 0.00003 --- use 19.712s\n",
      "Epoch:  248\n",
      "loss:  0.1306, val_loss 0.1937, val_score 0.1938, best_val_score 0.1938, lr 0.00003 --- use 19.607s\n",
      "Epoch:  249\n",
      "loss:  0.1305, val_loss 0.1939, val_score 0.1940, best_val_score 0.1938, lr 0.00003 --- use 19.615s\n",
      "Epoch:  250\n",
      "loss:  0.1303, val_loss 0.1938, val_score 0.1939, best_val_score 0.1938, lr 0.00003 --- use 19.850s\n",
      "Epoch:  251\n",
      "loss:  0.1305, val_loss 0.1936, val_score 0.1938, best_val_score 0.1938, lr 0.00003 --- use 19.793s\n",
      "Epoch:  252\n",
      "loss:  0.1304, val_loss 0.1939, val_score 0.1941, best_val_score 0.1938, lr 0.00003 --- use 19.577s\n",
      "Epoch:  253\n",
      "loss:  0.1299, val_loss 0.1939, val_score 0.1940, best_val_score 0.1938, lr 0.00003 --- use 19.870s\n",
      "Epoch:  254\n",
      "loss:  0.1300, val_loss 0.1937, val_score 0.1939, best_val_score 0.1938, lr 0.00003 --- use 19.797s\n",
      "Epoch:  255\n",
      "loss:  0.1300, val_loss 0.1940, val_score 0.1942, best_val_score 0.1938, lr 0.00003 --- use 19.739s\n",
      "Epoch:  256\n",
      "loss:  0.1298, val_loss 0.1940, val_score 0.1942, best_val_score 0.1938, lr 0.00003 --- use 19.778s\n",
      "Epoch:  257\n",
      "Epoch   258: reducing learning rate of group 0 to 1.5625e-05.\n",
      "loss:  0.1297, val_loss 0.1937, val_score 0.1939, best_val_score 0.1938, lr 0.00003 --- use 19.645s\n",
      "Epoch:  258\n",
      "loss:  0.1292, val_loss 0.1936, val_score 0.1938, best_val_score 0.1938, lr 0.00002 --- use 19.988s\n",
      "Epoch:  259\n",
      "loss:  0.1286, val_loss 0.1936, val_score 0.1938, best_val_score 0.1938, lr 0.00002 --- use 19.911s\n",
      "Epoch:  260\n",
      "loss:  0.1287, val_loss 0.1936, val_score 0.1938, best_val_score 0.1938, lr 0.00002 --- use 19.667s\n",
      "Epoch:  261\n",
      "loss:  0.1287, val_loss 0.1937, val_score 0.1939, best_val_score 0.1938, lr 0.00002 --- use 19.771s\n",
      "Epoch:  262\n",
      "loss:  0.1285, val_loss 0.1937, val_score 0.1939, best_val_score 0.1938, lr 0.00002 --- use 19.822s\n",
      "Epoch:  263\n",
      "loss:  0.1284, val_loss 0.1935, val_score 0.1937, best_val_score 0.1937, lr 0.00002 --- use 19.849s\n",
      "Epoch:  264\n",
      "loss:  0.1281, val_loss 0.1936, val_score 0.1937, best_val_score 0.1937, lr 0.00002 --- use 19.739s\n",
      "Epoch:  265\n",
      "loss:  0.1284, val_loss 0.1937, val_score 0.1938, best_val_score 0.1937, lr 0.00002 --- use 19.777s\n",
      "Epoch:  266\n",
      "loss:  0.1282, val_loss 0.1936, val_score 0.1938, best_val_score 0.1937, lr 0.00002 --- use 19.708s\n",
      "Epoch:  267\n",
      "loss:  0.1282, val_loss 0.1936, val_score 0.1938, best_val_score 0.1937, lr 0.00002 --- use 19.706s\n",
      "Epoch:  268\n",
      "loss:  0.1282, val_loss 0.1937, val_score 0.1939, best_val_score 0.1937, lr 0.00002 --- use 19.927s\n",
      "Epoch:  269\n",
      "loss:  0.1280, val_loss 0.1937, val_score 0.1938, best_val_score 0.1937, lr 0.00002 --- use 19.816s\n",
      "Epoch:  270\n",
      "loss:  0.1281, val_loss 0.1938, val_score 0.1940, best_val_score 0.1937, lr 0.00002 --- use 19.748s\n",
      "Epoch:  271\n",
      "loss:  0.1281, val_loss 0.1936, val_score 0.1938, best_val_score 0.1937, lr 0.00002 --- use 19.699s\n",
      "Epoch:  272\n",
      "loss:  0.1282, val_loss 0.1938, val_score 0.1939, best_val_score 0.1937, lr 0.00002 --- use 19.830s\n",
      "Epoch:  273\n",
      "loss:  0.1280, val_loss 0.1938, val_score 0.1940, best_val_score 0.1937, lr 0.00002 --- use 19.782s\n",
      "Epoch:  274\n",
      "Epoch   275: reducing learning rate of group 0 to 7.8125e-06.\n",
      "loss:  0.1279, val_loss 0.1938, val_score 0.1940, best_val_score 0.1937, lr 0.00002 --- use 19.671s\n",
      "Epoch:  275\n",
      "loss:  0.1275, val_loss 0.1936, val_score 0.1938, best_val_score 0.1937, lr 0.00001 --- use 19.770s\n",
      "Epoch:  276\n",
      "loss:  0.1273, val_loss 0.1936, val_score 0.1938, best_val_score 0.1937, lr 0.00001 --- use 19.903s\n",
      "Epoch:  277\n",
      "loss:  0.1272, val_loss 0.1937, val_score 0.1939, best_val_score 0.1937, lr 0.00001 --- use 19.753s\n",
      "Epoch:  278\n",
      "loss:  0.1271, val_loss 0.1936, val_score 0.1938, best_val_score 0.1937, lr 0.00001 --- use 19.800s\n",
      "Epoch:  279\n",
      "loss:  0.1272, val_loss 0.1936, val_score 0.1938, best_val_score 0.1937, lr 0.00001 --- use 19.798s\n",
      "Epoch:  280\n",
      "loss:  0.1272, val_loss 0.1937, val_score 0.1938, best_val_score 0.1937, lr 0.00001 --- use 19.767s\n",
      "Epoch:  281\n",
      "loss:  0.1273, val_loss 0.1937, val_score 0.1939, best_val_score 0.1937, lr 0.00001 --- use 19.851s\n",
      "Epoch:  282\n",
      "loss:  0.1273, val_loss 0.1937, val_score 0.1939, best_val_score 0.1937, lr 0.00001 --- use 19.809s\n",
      "Epoch:  283\n",
      "loss:  0.1271, val_loss 0.1936, val_score 0.1937, best_val_score 0.1937, lr 0.00001 --- use 19.658s\n",
      "Early Stop\n",
      "Fold:  1\n",
      "Unsctrict scale - leakage..\n",
      "training data samples, val data samples:  (60122, 80, 22) (15328, 80, 22)\n",
      "Model Size: 5696501\n",
      "Epoch:  0\n",
      "loss:  2.5608, val_loss 1.5021, val_score 1.5020, best_val_score 1.5020, lr 0.00100 --- use 19.783s\n",
      "Epoch:  1\n",
      "loss:  1.2355, val_loss 1.1185, val_score 1.1185, best_val_score 1.1185, lr 0.00100 --- use 19.733s\n",
      "Epoch:  2\n",
      "loss:  0.9984, val_loss 0.8975, val_score 0.8975, best_val_score 0.8975, lr 0.00100 --- use 19.766s\n",
      "Epoch:  3\n",
      "loss:  0.8860, val_loss 0.7966, val_score 0.7966, best_val_score 0.7966, lr 0.00100 --- use 19.683s\n",
      "Epoch:  4\n",
      "loss:  0.7586, val_loss 0.7001, val_score 0.7001, best_val_score 0.7001, lr 0.00100 --- use 19.733s\n",
      "Epoch:  5\n",
      "loss:  0.7132, val_loss 0.6990, val_score 0.6991, best_val_score 0.6991, lr 0.00100 --- use 19.672s\n",
      "Epoch:  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.6742, val_loss 0.6671, val_score 0.6671, best_val_score 0.6671, lr 0.00100 --- use 19.685s\n",
      "Epoch:  7\n",
      "loss:  0.6327, val_loss 0.6069, val_score 0.6069, best_val_score 0.6069, lr 0.00100 --- use 19.945s\n",
      "Epoch:  8\n",
      "loss:  0.6200, val_loss 0.6305, val_score 0.6306, best_val_score 0.6069, lr 0.00100 --- use 19.554s\n",
      "Epoch:  9\n",
      "loss:  0.6205, val_loss 0.5587, val_score 0.5587, best_val_score 0.5587, lr 0.00100 --- use 19.666s\n",
      "Epoch:  10\n",
      "loss:  0.5487, val_loss 0.5706, val_score 0.5707, best_val_score 0.5587, lr 0.00100 --- use 19.815s\n",
      "Epoch:  11\n",
      "loss:  0.5233, val_loss 0.5065, val_score 0.5065, best_val_score 0.5065, lr 0.00100 --- use 19.803s\n",
      "Epoch:  12\n",
      "loss:  0.5030, val_loss 0.5180, val_score 0.5180, best_val_score 0.5065, lr 0.00100 --- use 19.680s\n",
      "Epoch:  13\n",
      "loss:  0.4932, val_loss 0.4711, val_score 0.4711, best_val_score 0.4711, lr 0.00100 --- use 19.776s\n",
      "Epoch:  14\n",
      "loss:  0.5087, val_loss 0.4833, val_score 0.4834, best_val_score 0.4711, lr 0.00100 --- use 19.703s\n",
      "Epoch:  15\n",
      "loss:  0.4771, val_loss 0.4896, val_score 0.4896, best_val_score 0.4711, lr 0.00100 --- use 19.685s\n",
      "Epoch:  16\n",
      "loss:  0.4524, val_loss 0.4461, val_score 0.4461, best_val_score 0.4461, lr 0.00100 --- use 19.735s\n",
      "Epoch:  17\n",
      "loss:  0.4373, val_loss 0.4376, val_score 0.4376, best_val_score 0.4376, lr 0.00100 --- use 19.720s\n",
      "Epoch:  18\n",
      "loss:  0.4277, val_loss 0.4395, val_score 0.4395, best_val_score 0.4376, lr 0.00100 --- use 19.838s\n",
      "Epoch:  19\n",
      "loss:  0.4371, val_loss 0.4381, val_score 0.4381, best_val_score 0.4376, lr 0.00100 --- use 19.613s\n",
      "Epoch:  20\n",
      "loss:  0.4561, val_loss 0.4452, val_score 0.4453, best_val_score 0.4376, lr 0.00100 --- use 19.693s\n",
      "Epoch:  21\n",
      "loss:  0.4429, val_loss 0.4211, val_score 0.4211, best_val_score 0.4211, lr 0.00100 --- use 19.830s\n",
      "Epoch:  22\n",
      "loss:  0.4062, val_loss 0.4257, val_score 0.4257, best_val_score 0.4211, lr 0.00100 --- use 19.649s\n",
      "Epoch:  23\n",
      "loss:  0.4259, val_loss 0.4118, val_score 0.4118, best_val_score 0.4118, lr 0.00100 --- use 19.797s\n",
      "Epoch:  24\n",
      "loss:  0.4189, val_loss 0.4120, val_score 0.4120, best_val_score 0.4118, lr 0.00100 --- use 19.667s\n",
      "Epoch:  25\n",
      "loss:  0.4035, val_loss 0.4162, val_score 0.4163, best_val_score 0.4118, lr 0.00100 --- use 19.603s\n",
      "Epoch:  26\n",
      "loss:  0.3779, val_loss 0.3903, val_score 0.3904, best_val_score 0.3904, lr 0.00100 --- use 19.905s\n",
      "Epoch:  27\n",
      "loss:  0.3723, val_loss 0.3708, val_score 0.3708, best_val_score 0.3708, lr 0.00100 --- use 19.756s\n",
      "Epoch:  28\n",
      "loss:  0.4019, val_loss 0.4167, val_score 0.4167, best_val_score 0.3708, lr 0.00100 --- use 19.765s\n",
      "Epoch:  29\n",
      "loss:  0.3955, val_loss 0.3788, val_score 0.3788, best_val_score 0.3708, lr 0.00100 --- use 19.576s\n",
      "Epoch:  30\n",
      "loss:  0.3925, val_loss 0.3676, val_score 0.3676, best_val_score 0.3676, lr 0.00100 --- use 19.710s\n",
      "Epoch:  31\n",
      "loss:  0.3581, val_loss 0.3490, val_score 0.3490, best_val_score 0.3490, lr 0.00100 --- use 19.930s\n",
      "Epoch:  32\n",
      "loss:  0.3455, val_loss 0.3596, val_score 0.3596, best_val_score 0.3490, lr 0.00100 --- use 19.672s\n",
      "Epoch:  33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48307/1608391894.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Kaggle/GBVPP/notebook/../src/train_helper.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(train_df, config)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"skip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mbest_valid_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mfolds_val_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_valid_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'folds score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds_val_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Kaggle/GBVPP/notebook/../src/train_helper.py\u001b[0m in \u001b[0;36mrun_fold\u001b[0;34m(fold, original_train_df, config, swa_start_step, swa_start_epoch, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m                       swa_start_step=swa_start_step, swa_start_epoch=swa_start_epoch)\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     trainer.fit(\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Kaggle/GBVPP/notebook/../src/train_helper.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, train_loader, valid_loader, save_path)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Kaggle/GBVPP/notebook/../src/train_helper.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_helper.training_loop(train.copy(), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T04:20:15.641744Z",
     "start_time": "2021-10-19T04:20:15.472832Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T04:32:42.425463Z",
     "start_time": "2021-10-19T04:32:35.116116Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.194800e+06\n",
      "mean     1.122878e+01\n",
      "std      8.095154e+00\n",
      "min     -2.009307e+00\n",
      "25%      6.325120e+00\n",
      "50%      7.040617e+00\n",
      "75%      1.369039e+01\n",
      "max      6.485606e+01\n",
      "Name: pressure, dtype: float64\n",
      "test file saved to: /home/vincent/Kaggle/GBVPP/output/fork//submission.csv\n"
     ]
    }
   ],
   "source": [
    "test_avg = infer_helper.get_test_avg(train.query(\"fold==0\").copy(), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T04:32:43.329010Z",
     "start_time": "2021-10-19T04:32:43.306518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pressure</th>\n",
       "      <th>preds_fold0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.825046</td>\n",
       "      <td>5.825046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.764474</td>\n",
       "      <td>5.764474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.769022</td>\n",
       "      <td>7.769022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11.641850</td>\n",
       "      <td>11.641850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12.343712</td>\n",
       "      <td>12.343712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035995</th>\n",
       "      <td>6035996</td>\n",
       "      <td>3.917940</td>\n",
       "      <td>3.917940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035996</th>\n",
       "      <td>6035997</td>\n",
       "      <td>3.932015</td>\n",
       "      <td>3.932015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035997</th>\n",
       "      <td>6035998</td>\n",
       "      <td>3.891809</td>\n",
       "      <td>3.891809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035998</th>\n",
       "      <td>6035999</td>\n",
       "      <td>4.140372</td>\n",
       "      <td>4.140372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035999</th>\n",
       "      <td>6036000</td>\n",
       "      <td>4.014814</td>\n",
       "      <td>4.014814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1194800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id   pressure  preds_fold0\n",
       "0              1   5.825046     5.825046\n",
       "1              2   5.764474     5.764474\n",
       "2              3   7.769022     7.769022\n",
       "3              4  11.641850    11.641850\n",
       "4              5  12.343712    12.343712\n",
       "...          ...        ...          ...\n",
       "6035995  6035996   3.917940     3.917940\n",
       "6035996  6035997   3.932015     3.932015\n",
       "6035997  6035998   3.891809     3.891809\n",
       "6035998  6035999   4.140372     4.140372\n",
       "6035999  6036000   4.014814     4.014814\n",
       "\n",
       "[1194800 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T04:32:58.715457Z",
     "start_time": "2021-10-19T04:32:58.575178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           5.837492\n",
       "1           5.907794\n",
       "2           7.876254\n",
       "3          11.742872\n",
       "4          12.234987\n",
       "             ...    \n",
       "6035995     3.869032\n",
       "6035996     3.869032\n",
       "6035997     3.798729\n",
       "6035998     4.079938\n",
       "6035999     3.869032\n",
       "Name: pressure, Length: 1194800, dtype: float32"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.query(\"fold==0\")['pressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T04:29:49.123818Z",
     "start_time": "2021-10-19T04:29:48.890622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_avg[\"pressure\"].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T04:29:51.360763Z",
     "start_time": "2021-10-19T04:29:51.148696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"pressure\"].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
