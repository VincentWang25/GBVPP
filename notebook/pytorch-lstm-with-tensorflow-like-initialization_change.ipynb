{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a03b14a9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.011638,
     "end_time": "2021-10-12T02:00:26.378851",
     "exception": false,
     "start_time": "2021-10-12T02:00:26.367213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PyTorch LSTM with TensorFlow-like initialization\n",
    "\n",
    "My purpose for this notebook is to reproduce,\n",
    "\n",
    "Dmitry Uarov: https://www.kaggle.com/dmitryuarov/ventilator-pressure-eda-lstm-0-189/notebook\n",
    "\n",
    "with PyTorch (public LB 0.189). This sounds easy, but not always. I first got a significantly worse score ~ 0.3 using the same features and the model. Since I have heard that the weight initializations are different between PyTorch and TensorFlow, I am trying to make them as similar as I can in this notebook.\n",
    "\n",
    "The weight initializations are as follows, according to the official documents\n",
    "([Keras](https://keras.io/api/layers/recurrent_layers/lstm/), \n",
    "[PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)):\n",
    "\n",
    "| Parameter | TensorFlow/Keras | PyTorch |\n",
    "| ---       | --- | --- |\n",
    "| weight_ih | xavier uniform | uniform √hidden_size |\n",
    "| weight_hh | orthogonal     | same as above                    |\n",
    "| bias      | 1 for forget gate, 0 other wise | same as above    |\n",
    "| linear    | xavier uniform | uniform √input_size |\n",
    "\n",
    "I wrote `_reinitialize()` in class `Model`, which is the main content of this notebook.\n",
    "\n",
    "For me, using Xavier uniform for the fully connected (linear) after the LSTM was most important (which \n",
    "looks least important to me, though). TensorFlow initialization scheme for LSTM helped, too.\n",
    "\n",
    "Remaining uncertainties:\n",
    "\n",
    "* One LSTM weight is actually 4 matrices packed in one tensor. Should I initialize 4 matrices separately?\n",
    "* Two biases bi and bh in Pytorch LSTM seem redundant. For the forget gate, I only set one of them to 1 because I saw somewhere that Keras have only one bias, but I am not sure.\n",
    "\n",
    "Change log\n",
    "* Version 3: Public score is computed from 5 models (5 folds) trained locally. It was from 2 folds trained in notebook in version 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9446f888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T14:50:26.866480Z",
     "start_time": "2021-10-13T14:50:25.955849Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-12T02:00:26.404232Z",
     "iopub.status.busy": "2021-10-12T02:00:26.402776Z",
     "iopub.status.idle": "2021-10-12T02:00:31.769920Z",
     "shell.execute_reply": "2021-10-12T02:00:31.769361Z",
     "shell.execute_reply.started": "2021-10-12T01:57:49.186647Z"
    },
    "papermill": {
     "duration": 5.380848,
     "end_time": "2021-10-12T02:00:31.770084",
     "exception": false,
     "start_time": "2021-10-12T02:00:26.389236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import argparse\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "debug = False\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11844292",
   "metadata": {
    "papermill": {
     "duration": 0.011016,
     "end_time": "2021-10-12T02:00:31.792103",
     "exception": false,
     "start_time": "2021-10-12T02:00:31.781087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Features and Dataset\n",
    "\n",
    "From: https://www.kaggle.com/dmitryuarov/ventilator-pressure-eda-lstm-0-189/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3002cb1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T14:50:27.766927Z",
     "start_time": "2021-10-13T14:50:27.756349Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-12T02:00:31.830536Z",
     "iopub.status.busy": "2021-10-12T02:00:31.828777Z",
     "iopub.status.idle": "2021-10-12T02:00:31.831143Z",
     "shell.execute_reply": "2021-10-12T02:00:31.831556Z",
     "shell.execute_reply.started": "2021-10-12T01:57:54.246795Z"
    },
    "papermill": {
     "duration": 0.029085,
     "end_time": "2021-10-12T02:00:31.831673",
     "exception": false,
     "start_time": "2021-10-12T02:00:31.802588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "\n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "\n",
    "    df['u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n",
    "    df['u_in_lag4'] = df['u_in'].shift(4).fillna(0)\n",
    "\n",
    "    df['R'] = df['R'].astype(str)\n",
    "    df['C'] = df['C'].astype(str)\n",
    "    df = pd.get_dummies(df)\n",
    "\n",
    "    g = df.groupby('breath_id')['u_in']\n",
    "    df['ewm_u_in_mean'] = g.ewm(halflife=10).mean()\\\n",
    "                           .reset_index(level=0, drop=True)\n",
    "    df['ewm_u_in_std'] = g.ewm(halflife=10).std()\\\n",
    "                          .reset_index(level=0, drop=True)\n",
    "    df['ewm_u_in_corr'] = g.ewm(halflife=10).corr()\\\n",
    "                           .reset_index(level=0, drop=True)\n",
    "\n",
    "    df['rolling_10_mean'] = g.rolling(window=10, min_periods=1).mean()\\\n",
    "                             .reset_index(level=0, drop=True)\n",
    "    df['rolling_10_max'] = g.rolling(window=10, min_periods=1).max()\\\n",
    "                            .reset_index(level=0, drop=True)\n",
    "    df['rolling_10_std'] = g.rolling(window=10, min_periods=1).std()\\\n",
    "                            .reset_index(level=0, drop=True)\n",
    "\n",
    "    df['expand_mean'] = g.expanding(2).mean()\\\n",
    "                         .reset_index(level=0, drop=True)\n",
    "    df['expand_max'] = g.expanding(2).max()\\\n",
    "                        .reset_index(level=0, drop=True)\n",
    "    df['expand_std'] = g.expanding(2).std()\\\n",
    "                        .reset_index(level=0, drop=True)\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    df.drop(['id', 'breath_id'], axis=1, inplace=True)\n",
    "    if 'pressure' in df.columns:\n",
    "        df.drop('pressure', axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, w):\n",
    "        if y is None:\n",
    "            y = np.zeros(len(X), dtype=np.float32)\n",
    "\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "        self.w = w.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i], self.w[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd32b03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T14:50:41.640614Z",
     "start_time": "2021-10-13T14:50:41.637747Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-12T02:00:31.858500Z",
     "iopub.status.busy": "2021-10-12T02:00:31.857935Z",
     "iopub.status.idle": "2021-10-12T02:05:28.752117Z",
     "shell.execute_reply": "2021-10-12T02:05:28.752538Z",
     "shell.execute_reply.started": "2021-10-12T01:57:54.264917Z"
    },
    "papermill": {
     "duration": 296.910751,
     "end_time": "2021-10-12T02:05:28.752693",
     "exception": false,
     "start_time": "2021-10-12T02:00:31.841942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 100*1024 if debug else None\n",
    "\n",
    "di = \"/media/vincent/Backup/kaggle_data/ventilator-pressure-prediction/\"\n",
    "train = pd.read_csv(di + 'train.csv', nrows=n)\n",
    "test = pd.read_csv(di + 'test.csv', nrows=n)\n",
    "submit = pd.read_csv(di + 'sample_submission.csv', nrows=n)\n",
    "\n",
    "\n",
    "input_size = 22#X_all.shape[2]\n",
    "\n",
    "#print(len(X_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9edcb9",
   "metadata": {
    "papermill": {
     "duration": 0.010735,
     "end_time": "2021-10-12T02:05:28.774347",
     "exception": false,
     "start_time": "2021-10-12T02:05:28.763612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ebf52c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T14:50:45.324981Z",
     "start_time": "2021-10-13T14:50:45.315578Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-12T02:05:28.810195Z",
     "iopub.status.busy": "2021-10-12T02:05:28.808624Z",
     "iopub.status.idle": "2021-10-12T02:05:28.810822Z",
     "shell.execute_reply": "2021-10-12T02:05:28.811221Z",
     "shell.execute_reply.started": "2021-10-12T01:57:57.715535Z"
    },
    "papermill": {
     "duration": 0.026389,
     "end_time": "2021-10-12T02:05:28.811336",
     "exception": false,
     "start_time": "2021-10-12T02:05:28.784947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        hidden = [400, 300, 200, 100]\n",
    "        super().__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden[0],\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(2 * hidden[0], hidden[1],\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.lstm3 = nn.LSTM(2 * hidden[1], hidden[2],\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.lstm4 = nn.LSTM(2 * hidden[2], hidden[3],\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(2 * hidden[3], 50)\n",
    "        self.selu = nn.SELU()\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "        self._reinitialize()\n",
    "\n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'lstm' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "            elif 'fc' in name:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'bias' in name:\n",
    "                    p.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.selu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac11b794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T14:50:46.126039Z",
     "start_time": "2021-10-13T14:50:46.024314Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-12T02:05:28.837005Z",
     "iopub.status.busy": "2021-10-12T02:05:28.836385Z",
     "iopub.status.idle": "2021-10-12T02:05:29.073883Z",
     "shell.execute_reply": "2021-10-12T02:05:29.074307Z",
     "shell.execute_reply.started": "2021-10-12T01:57:57.730349Z"
    },
    "papermill": {
     "duration": 0.252069,
     "end_time": "2021-10-12T02:05:29.074455",
     "exception": false,
     "start_time": "2021-10-12T02:05:28.822386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm1.weight_ih_l0               (1600, 22)\n",
      "lstm1.weight_hh_l0               (1600, 400)\n",
      "lstm1.bias_ih_l0                 (1600,)\n",
      "lstm1.bias_hh_l0                 (1600,)\n",
      "lstm1.weight_ih_l0_reverse       (1600, 22)\n",
      "lstm1.weight_hh_l0_reverse       (1600, 400)\n",
      "lstm1.bias_ih_l0_reverse         (1600,)\n",
      "lstm1.bias_hh_l0_reverse         (1600,)\n",
      "lstm2.weight_ih_l0               (1200, 800)\n",
      "lstm2.weight_hh_l0               (1200, 300)\n",
      "lstm2.bias_ih_l0                 (1200,)\n",
      "lstm2.bias_hh_l0                 (1200,)\n",
      "lstm2.weight_ih_l0_reverse       (1200, 800)\n",
      "lstm2.weight_hh_l0_reverse       (1200, 300)\n",
      "lstm2.bias_ih_l0_reverse         (1200,)\n",
      "lstm2.bias_hh_l0_reverse         (1200,)\n",
      "lstm3.weight_ih_l0               (800, 600)\n",
      "lstm3.weight_hh_l0               (800, 200)\n",
      "lstm3.bias_ih_l0                 (800,)\n",
      "lstm3.bias_hh_l0                 (800,)\n",
      "lstm3.weight_ih_l0_reverse       (800, 600)\n",
      "lstm3.weight_hh_l0_reverse       (800, 200)\n",
      "lstm3.bias_ih_l0_reverse         (800,)\n",
      "lstm3.bias_hh_l0_reverse         (800,)\n",
      "lstm4.weight_ih_l0               (400, 400)\n",
      "lstm4.weight_hh_l0               (400, 100)\n",
      "lstm4.bias_ih_l0                 (400,)\n",
      "lstm4.bias_hh_l0                 (400,)\n",
      "lstm4.weight_ih_l0_reverse       (400, 400)\n",
      "lstm4.weight_hh_l0_reverse       (400, 100)\n",
      "lstm4.bias_ih_l0_reverse         (400,)\n",
      "lstm4.bias_hh_l0_reverse         (400,)\n",
      "fc1.weight                       (50, 200)\n",
      "fc1.bias                         (50,)\n",
      "fc2.weight                       (1, 50)\n",
      "fc2.bias                         (1,)\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_size)\n",
    "for name, p in model.named_parameters():\n",
    "    print('%-32s %s' % (name, tuple(p.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64aff34",
   "metadata": {
    "papermill": {
     "duration": 0.011264,
     "end_time": "2021-10-12T02:05:29.097038",
     "exception": false,
     "start_time": "2021-10-12T02:05:29.085774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "587b13ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T14:50:48.072519Z",
     "start_time": "2021-10-13T14:50:48.068236Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-12T02:05:29.127116Z",
     "iopub.status.busy": "2021-10-12T02:05:29.126611Z",
     "iopub.status.idle": "2021-10-12T02:05:29.129655Z",
     "shell.execute_reply": "2021-10-12T02:05:29.130419Z",
     "shell.execute_reply.started": "2021-10-12T01:57:57.978884Z"
    },
    "papermill": {
     "duration": 0.02246,
     "end_time": "2021-10-12T02:05:29.130554",
     "exception": false,
     "start_time": "2021-10-12T02:05:29.108094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss()\n",
    "\n",
    "def evaluate(model, loader_val):\n",
    "    tb = time.time()\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    loss_sum = 0\n",
    "    score_sum = 0\n",
    "    n_sum = 0\n",
    "    y_pred_all = []\n",
    "\n",
    "    for ibatch, (x, y, w) in enumerate(loader_val):\n",
    "        n = y.size(0)\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        w = w.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x).squeeze()\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        n_sum += n\n",
    "        loss_sum += n*loss.item()\n",
    "        \n",
    "        y_pred_all.append(y_pred.cpu().detach().numpy())\n",
    "\n",
    "    loss_val = loss_sum / n_sum\n",
    "\n",
    "    model.train(was_training)\n",
    "\n",
    "    d = {'loss': loss_val,\n",
    "         'time': time.time() - tb,\n",
    "         'y_pred': np.concatenate(y_pred_all, axis=0)}\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3aa2f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T11:53:37.359687Z",
     "start_time": "2021-10-13T14:51:31.547988Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-12T02:05:29.168407Z",
     "iopub.status.busy": "2021-10-12T02:05:29.160144Z",
     "iopub.status.idle": "2021-10-12T07:01:43.872565Z",
     "shell.execute_reply": "2021-10-12T07:01:43.873288Z",
     "shell.execute_reply.started": "2021-10-12T01:57:57.989611Z"
    },
    "papermill": {
     "duration": 17774.731948,
     "end_time": "2021-10-12T07:01:43.873612",
     "exception": false,
     "start_time": "2021-10-12T02:05:29.141664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "epoch loss_train loss_val lr time\n",
      "  1  1.908844  3.738025 5.000e-04    65.2    2.0\n",
      "  2  1.061860  3.674722 5.000e-04    91.7    4.0\n",
      "  3  0.931622  3.477029 5.000e-04   117.5    6.0\n",
      "  4  0.868372  3.271382 5.000e-04   145.3    8.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15716/2043671290.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nfold = 5\n",
    "kfold = KFold(n_splits=nfold, shuffle=True, random_state=228)\n",
    "epochs = 2 if debug else 300\n",
    "lr = 5e-4\n",
    "batch_size = 256\n",
    "max_grad_norm = 1000\n",
    "log = {}\n",
    "\n",
    "for ifold, (idx_train, idx_val) in enumerate(kfold.split(train)):\n",
    "    print('Fold %d' % ifold)\n",
    "    tb = time.time()\n",
    "    model = Model(input_size)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=10)\n",
    "\n",
    "    train_fold, val_fold = train.iloc[idx_train,:],train.iloc[idx_val,:]\n",
    "    features = create_features(train_fold)\n",
    "    rs = sklearn.preprocessing.RobustScaler()\n",
    "    features = rs.fit_transform(features)  # => np.ndarray\n",
    "\n",
    "    X_train = features.reshape(-1, 80, features.shape[-1])\n",
    "    y_train = train_fold.pressure.values.reshape(-1, 80)\n",
    "    w_train = 1 - train_fold.u_out.values.reshape(-1, 80)  # weights for the score, but not used in this notebook\n",
    "    \n",
    "    X_val = create_features(val_fold)\n",
    "    X_val = rs.transform(X_val)\n",
    "    X_val = X_val.reshape(-1, 80, features.shape[-1])\n",
    "    y_val = val_fold.pressure.values.reshape(-1, 80)\n",
    "    w_val = 1 - val_fold.u_out.values.reshape(-1, 80)  # weights for the score, but not used in this notebook\n",
    "    \n",
    "    #     X_train = X_all[idx_train]\n",
    "    #     y_train = y_all[idx_train]\n",
    "    #     w_train = w_all[idx_train]\n",
    "\n",
    "    #     X_val = X_all[idx_val]\n",
    "    #     y_val = y_all[idx_val]\n",
    "    #     w_val = w_all[idx_val]\n",
    "\n",
    "    dataset_train = Dataset(X_train, y_train, w_train)\n",
    "    dataset_val = Dataset(X_val, y_val, w_val)\n",
    "    loader_train = torch.utils.data.DataLoader(dataset_train, shuffle=True,\n",
    "                         batch_size=batch_size, drop_last=True)\n",
    "    loader_val = torch.utils.data.DataLoader(dataset_val, shuffle=False,\n",
    "                         batch_size=batch_size, drop_last=False)\n",
    "\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "    lrs = []\n",
    "    time_val = 0\n",
    "    best_score = np.inf\n",
    "   \n",
    "    print('epoch loss_train loss_val lr time')\n",
    "    for iepoch in range(epochs):\n",
    "        loss_train = 0\n",
    "        n_sum = 0\n",
    "        \n",
    "        for ibatch, (x, y, w) in enumerate(loader_train):\n",
    "            n = y.size(0)\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(x).squeeze()\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss_train += n*loss.item()\n",
    "            n_sum += n\n",
    "\n",
    "            loss.backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        val = evaluate(model, loader_val)\n",
    "        loss_val = val['loss']\n",
    "        time_val += val['time']\n",
    "\n",
    "        losses_train.append(loss_train / n_sum)\n",
    "        losses_val.append(val['loss'])\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        print('%3d %9.6f %9.6f %7.3e %7.1f %6.1f' %\n",
    "              (iepoch + 1,\n",
    "               losses_train[-1], losses_val[-1], \n",
    "               lrs[-1], time.time() - tb, time_val))\n",
    "\n",
    "        scheduler.step(losses_val[-1])\n",
    "\n",
    "\n",
    "    ofilename = 'model%d.pth' % ifold\n",
    "    torch.save(model.state_dict(), ofilename)\n",
    "    print(ofilename, 'written')\n",
    "\n",
    "    log['fold%d' % ifold] = {\n",
    "        'loss_train': np.array(losses_train),\n",
    "        'loss_val': np.array(losses_val),\n",
    "        'learning_rate': np.array(lrs),\n",
    "        'y_pred': val['y_pred'],\n",
    "        'idx': idx_val\n",
    "    }\n",
    "    \n",
    "    if ifold >= 1: # due to time limit\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23008ed0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T14:33:28.460504Z",
     "start_time": "2021-10-13T14:33:28.460495Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-12T07:01:44.344732Z",
     "iopub.status.busy": "2021-10-12T07:01:44.344049Z",
     "iopub.status.idle": "2021-10-12T07:01:44.346827Z",
     "shell.execute_reply": "2021-10-12T07:01:44.347241Z",
     "shell.execute_reply.started": "2021-10-12T01:58:05.742829Z"
    },
    "papermill": {
     "duration": 0.181792,
     "end_time": "2021-10-12T07:01:44.347372",
     "exception": false,
     "start_time": "2021-10-12T07:01:44.165580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Fold loss_train loss_val best loss_val')\n",
    "for ifold in range(2):\n",
    "    d = log['fold%d' % ifold]\n",
    "    print('%4d %9.6f %9.6f %9.6f' % (ifold, d['loss_train'][-1], d['loss_val'][-1], np.min(d['loss_val'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda0d84",
   "metadata": {
    "papermill": {
     "duration": 0.168013,
     "end_time": "2021-10-12T07:01:44.676622",
     "exception": false,
     "start_time": "2021-10-12T07:01:44.508609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I trained 5 folds locally,\n",
    "\n",
    "```\n",
    "epoch loss_train loss_val\n",
    "0.119303  0.184425 \n",
    "0.105525  0.184154\n",
    "0.109591  0.179805\n",
    "0.127961  0.191654\n",
    "0.141102  0.202042\n",
    "```\n",
    "\n",
    "The original TensorFlow scores at the end are,\n",
    "\n",
    "```\n",
    "loss val_loss (epoch 300)\n",
    "0.1351 0.1902\n",
    "0.1365 0.1897\n",
    "0.1292 0.1972\n",
    "0.1221 0.1970\n",
    "0.1276 0.1976\n",
    "```\n",
    "\n",
    "I am satisfied with the similarity.\n",
    "\n",
    "Note that the loss here is the overall MAE including the expiratory phase, which is not the evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a288a",
   "metadata": {
    "papermill": {
     "duration": 0.161272,
     "end_time": "2021-10-12T07:01:44.999615",
     "exception": false,
     "start_time": "2021-10-12T07:01:44.838343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33e1fd47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-12T07:01:45.332980Z",
     "iopub.status.busy": "2021-10-12T07:01:45.331997Z",
     "iopub.status.idle": "2021-10-12T07:05:36.540026Z",
     "shell.execute_reply": "2021-10-12T07:05:36.540594Z",
     "shell.execute_reply.started": "2021-10-12T01:58:05.751240Z"
    },
    "papermill": {
     "duration": 231.378616,
     "end_time": "2021-10-12T07:05:36.540790",
     "exception": false,
     "start_time": "2021-10-12T07:01:45.162174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv written\n"
     ]
    }
   ],
   "source": [
    "features = create_features(test)\n",
    "features = rs.transform(features)\n",
    "\n",
    "X_test = features.reshape(-1, 80, features.shape[-1])\n",
    "y_test = np.zeros(len(features)).reshape(-1, 80)\n",
    "w_test = 1 - test.u_out.values.reshape(-1, 80)\n",
    "\n",
    "dataset_test = Dataset(X_test, y_test, w_test)\n",
    "loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size)\n",
    "\n",
    "y_pred_folds = np.zeros((len(test), 5), dtype=np.float32)\n",
    "for ifold in range(5):\n",
    "    model = Model(input_size)\n",
    "    model.to(device)\n",
    "    filename = '/kaggle/input/pytorchlstmwithtensorflowlikeinitialization/' \\\n",
    "               'model%d.pth' % ifold\n",
    "    model.load_state_dict(torch.load(filename, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    y_preds = []\n",
    "    for x, y, _ in loader_test:\n",
    "        x = x.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x).squeeze()\n",
    "\n",
    "        y_preds.append(y_pred.cpu().numpy())\n",
    "    \n",
    "    y_preds = np.concatenate(y_preds, axis=0)\n",
    "    y_pred_folds[:, ifold] = y_preds.flatten()\n",
    "\n",
    "submit.pressure = np.mean(y_pred_folds, axis=1)\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "print('submission.csv written')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2768dee",
   "metadata": {
    "papermill": {
     "duration": 0.164778,
     "end_time": "2021-10-12T07:05:36.875775",
     "exception": false,
     "start_time": "2021-10-12T07:05:36.710997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Minor differences from the original, with no reason.\n",
    "\n",
    "* Learning rate scheduler is ReduceLROnPlateau, which is used in [other notebooks](https://www.kaggle.com/tenffe/finetune-of-tensorflow-bidirectional-lstm);\n",
    "* I have not implemented early stopping;\n",
    "* random seeds other than kfold are not fixed in the original. Mine is not strictly deterministic either.\n",
    "\n",
    "There are more features, loss function, or better aggrigation of nfold predictions, and so on, in public notebooks, but my goal here is to reproduce score as good as TensorFlow using same model and features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18318.533399,
   "end_time": "2021-10-12T07:05:38.051156",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-12T02:00:19.517757",
   "version": "2.3.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
